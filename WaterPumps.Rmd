---
title: "Water Pumps"
author: Steven Gusenius, Zuber Saiyed, Margarita Linets
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, cache=TRUE)
```
## About this Project
Using data from Taarifa and the Tanzanian Ministry of Water, we set out to predict what could impact the state of water pumps. 

A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.

More information about the challenge and the dataset can be found here - https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/23/

## About the Dataset
The datasets for this project were downloaded from www.drivendata.org and consisted of a two files of comma separated format.  This first file contains 40 characteristic data of each water pump, indexed by a pump ID, to be used as predictors. A list of these predictors is provided in APPENDIX A.

The second file contains the state_group for each water pump, also indexed by pump ID.  The state_group is the response we are attempting to predict and indicates the condition of a water pump.  Its value can be:  Functional (F), FunctionalNeedsRepair (FNR), or NonFunctional(NF).  

In total, there is data for 59,400 water pumps.

## Data Cleaning  
*Data Modification* Initially the datasets were cleaned to make them compatible with processing. Primarily this consisted of addressing missing data and special characters.  Then the predictor data was merged with the response data into a single dataset.

*Data Excluded* Following the merge, the pump ID was elimianted as it is not a meaningful predictor.  One predictor, **recorded_by** was excluded because it was constant for all water pumps. Several other cartegorical predictors were eliminated for having an excessive number of (greater than 30) levels.  A list of these factor variables, and their associated number of levels, is available in APPENDIX B. This step was needed when Lasso was used.  This because Lasso requires the inputs to be of type *model.matrix*.  A model matrix creates a separate column of data for each level of each factor variable.  This has a detrimental impact on both memory requirements and processing speed.  In this case, the retention of all such factor variables exceeded the capacity of the R software.  Further, it is a reasonable assumption that if a large proportion of the data is spread across many nomial factor levels, that factor variable will have diminished predictive power.   

For model types based on Random Forest, however, no such model matrix was required.  As such, for these approaches a separate dataset containing these variables was retained.


## Data Exploration
Prior to model fitting, some effort was invested in understanding the content of the data.  Various hypotheses were made and then evaluated through a number of simple, ad hoc analyses.

One such analysis was a data visualization where the frequency of the three **state_groups**, for each **region**, was plotted at the center of the respctive region on a map of Tanzania.  This provide an understanding of how the regions were dispersed throughout the country, an indication of how many water pumps were contained in each region, and quick assessment of whether each **region** had similar proportions of F, FNR, and NF water pumps.

From this map we observe that the distribution of the **regions** show no clear geometric pattern.  Further, likely due to differing sizes and populations, there is a lot of variability in the number of water pumps per **region**. Finally, it seems that if anything can be gleaned from the frequency data, it is that districts with the fewest water pumps might have a larger number that are NF.  However, this requires further study.


Given its ability as a variable selector, Lasso fitting was employed as a means of assessing the which variables had the largest impact on the response. This ultimately allowed for a subset of relevant variables to be used in future fittings. A list of the variables identified relevant is provided in APPENDIX C.

    - 
    - Random Forest and Binomial Lasso perform variable selection
    
## Fit Approaches
    - training vs validation (size, purpose, etc)
    - Approach selection... lack of numerical data restricted what techniques could be used (nothing relying on euclidean distances)
    - relatively few FNR points made resulted, meant prediction performance of FNR was poor with some models types.
    - Approaches to deal with that: data balancing, one-vs-one binomial
    - description of each approach
    
    Binary Lasso Model (using One vs One)
    Random Forest
    Random Forest with Boosting 

**MORE METADATA TO FOLLOW**
```{r}
#Libraries
library_list = list('ggplot2','glmnet','ggmap','reshape2', 'randomForest', 'gbm', 'caret','knitr')
lapply(library_list, require, character.only = TRUE)
```

## Import Data

```{r}
# Define train_values_url
train_values_url <- "http://s3.amazonaws.com/drivendata/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv"
WaterPumps_value = read.csv(train_values_url, header=TRUE, stringsAsFactors = FALSE)
# Define train_labels_url
train_labels_url <- "http://s3.amazonaws.com/drivendata/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv"
WaterPumps_label = read.csv(train_labels_url, header=TRUE, stringsAsFactors = TRUE)
# Define test_values_url
test_values_url <- "http://s3.amazonaws.com/drivendata/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv"
test_values = read.csv(test_values_url, header=TRUE, stringsAsFactors=TRUE)
```

## Data Cleaning:

```{r}
#Merge into a single datset
WaterPumps = merge(WaterPumps_value, WaterPumps_label, by='id')

#Convert all character variables to upper case and remove non alpha numeric variables 
charcols = which(sapply(WaterPumps,is.character))
WaterPumps[,charcols] <- sapply(WaterPumps[,charcols], toupper)
WaterPumps[,charcols] <- sapply(WaterPumps[, charcols], function(x) gsub("[^[:alnum:]=\\.]",'',x))

#Drop id variables - it is not a meaningful predict, just a record counter
WaterPumps = WaterPumps[, -which(names(WaterPumps) %in% c('id','recorded_by'))]
```


```{r}
# Clean Data: Filter out variables with more than 30 factors - model matrix becomes too large
KeepVars = setNames(data.frame(sapply(WaterPumps[,which(sapply(WaterPumps, is.character))], function(x){if(length(unique(x))>30){FALSE} else {TRUE}})),
                    c('factorlevels'))
KeepVars$vars = rownames(KeepVars)
WaterPumps = WaterPumps[,-which(names(WaterPumps) %in% KeepVars$vars[which(KeepVars$factorlevels==FALSE)])]

# Remove Multicollinearity

```

## Exploratory Analysis

```{r}
## Aggregate waterpump count by region
regional_geocodes = cbind.data.frame(data.frame("region" = unique(WaterPumps$region)),
                                     setNames(data.frame(t(data.frame(lapply(lapply(unique(WaterPumps$region), function(x)paste0(x, ', Tanzania')), 
                                                                             function(x) as.numeric(geocode(x)))))), c('longitude','latitude')))

#Drop Row Names
rownames(regional_geocodes) <- c()
#Aggregate Pump Kinds by Region
PumpsByRegion=dcast(WaterPumps, region~status_group, fun=length, value.var = 'status_group')
PumpsByRegion = merge(PumpsByRegion, regional_geocodes, id='region')
colnames(PumpsByRegion)=c("region", "functional","needsrepair", "nonfunctional","longitude","latitude" )

Tanzania = as.numeric(geocode("Tanzania"))
Tanzania_Map = ggmap(get_googlemap(center=Tanzania, scale=2, zoom=6))+
    geom_point(aes(x=longitude, y=latitude), data=PumpsByRegion, col='blue', alpha=0.4,
               size=PumpsByRegion$functional*0.01)+
    geom_point(aes(x=longitude, y=latitude), data=PumpsByRegion, col='orange', alpha=0.4,
               size=PumpsByRegion$needsrepair*0.01)+
    geom_point(aes(x=longitude, y=latitude), data=PumpsByRegion, col='red', alpha=0.4,
               size=PumpsByRegion$nonfunctional*0.01)+
    ggtitle('Number of Pumps by Status by Region')
Tanzania_Map
```

```{r}
# Water Pump Position Plot

# Convert Latitude/Longitude to kilometers. 
#  - Use 1862 meters per nautical mile (nmi).
#  - Uses 60 nmi per degree of latitude
#  - Uses 60 nmi per degree of longitude (at the equator)
#  - Assumes spherical earth (for logitudes above and below the equator)

# Convert lat long to xy 
x = 1.862 * 60 * cos(WaterPumps$latitude*pi/180)*(WaterPumps$longitude)
y = 1.862 * 60 *(WaterPumps$latitude)

# Get Water Pump Operational State
z = as.factor(WaterPumps_label[,2])

# Plot Water pump Locations, color coded by OPerational state.  Use [x>10] indexing to elimninate bogus zeroed data entries.
plot(x[x>10],y[x>10],col=c("green","blue","red")[z[x>10]], xlab = 'Longitude (km)', ylab = 'Latitude (km)', pch = 18, main = 'Water Pump Locations (from Lon,Lat = [0,0])')
grid()
legend('bottomleft',legend = c('Functional','Repair','Non-Functional'), pch=18, col = c('green','blue','red'),inset = 0.01)
```

## Train & Validation Split

```{r}
# Take Only Non-Missing Values
WaterPumps <- WaterPumps[complete.cases(WaterPumps),]

# Create Model Matrix
modelmatrix = model.matrix(status_group~., WaterPumps)[,-1]

# Train and Validation Split
set.seed(500)
size=round(nrow(WaterPumps)*0.7)
train = sample(nrow(WaterPumps), size=size,replace = FALSE)
valid = which(!seq(1, nrow(WaterPumps), 1) %in% train)

train.x = modelmatrix[train,]
valid.x = modelmatrix[valid,]
train.y = WaterPumps$status_group[train]
valid.y = WaterPumps$status_group[valid]
```

## Results

# Binary Outcome Lasso

```{r}
# Binary Outcome Lasso 
temp = rep(0,length(valid.y))
Predict.Valid = data.frame(model1 = temp,
                       model2 = temp,
                       model3 = temp)

temp = rep(0,length(train.y))
Predict.Train = data.frame(model1 = temp,
                       model2 = temp,
                       model3 = temp)

LevelName = ''
train.df = cbind.data.frame(train.x, data.frame('status_group'=train.y))
i = 0

# Build a model for Each Level and record its predictions
for (each in levels(train.y)){

    i = i + 1
    LevelName[i] = each
    temp.y = train.y
    levels(temp.y) = list(other=c(levels(train.y)[!levels(train.y) %in% each]),selected=each)
    
    # Fit LASSO
    fit.lasso = glmnet(train.x, temp.y, alpha=1, family = 'binomial')
    
    # Cross-Validate to Find Best Lambda
    lasso.cv.out = cv.glmnet(train.x,temp.y,alpha=1,family = 'binomial')
    minlambda = lasso.cv.out$lambda.min
    
    # fitted = predict(fit.lasso, newx=train.x, s=minlambda, type='class')
    Predict.Valid[,i] = predict(fit.lasso, newx=valid.x, s=minlambda, type = 'response')
    Predict.Train[,i] = predict(fit.lasso, newx=train.x, s=minlambda, type = 'response')
}

bestCatValid = rep('other',length(valid.y))

for (k in 1 : length(valid.y)) {
    bestCatValid[k] = LevelName[which.max(Predict.Valid[k,])]
}

bestCatTrain = rep('other',length(train.y))

for (k in 1 : length(train.y)) {
    bestCatTrain[k] = LevelName[which.max(Predict.Train[k,])]
}

Binary.ConfTrain = confusionMatrix(bestCatTrain, train.y)
Binary.ConfValid = confusionMatrix(bestCatValid, valid.y)
```


```{r}
kable(data.frame(Binary.ConfTrain$byClass)[,c('Sensitivity', 'Specificity', 'Precision','Recall','Balanced.Accuracy')], 
      caption = 'Training Data Performance')

kable(data.frame(Binary.ConfValid$byClass)[,c('Sensitivity', 'Specificity', 'Precision','Recall','Balanced.Accuracy')], 
      caption = 'Validation Data Performance')
```

# Random Forest 

```{r}
# Random Forest 
set.seed(500)
WaterPumps[sapply(WaterPumps, is.character)] <- lapply(WaterPumps[, which(sapply(WaterPumps, is.character))], as.factor)
RandomForest.mod = randomForest(status_group~., data=WaterPumps[train,], importance=TRUE, ntree=100)
#importance(RandomForest.mod)
varImpPlot(RandomForest.mod)
# Prediction error in the training data set
rf.fitted = predict(RandomForest.mod, WaterPumps[train,])
RF.ConfTrain = confusionMatrix(rf.fitted, train.y)
# Prediction error in the validation dataset
rf.predicted = predict(RandomForest.mod, WaterPumps[valid,])
RF.ConfValid = confusionMatrix(rf.predicted, valid.y)
```

From the random forest procedure, we obtained training set prediction accuracy of `r round(ConfTrain$overall["Accuracy"][[1]],3)*100`%. By contrast, in the validation set, the prediction accuracy was only `r round(ConfValid$overall["Accuracy"][[1]],3)*100`%. 


```{r}
kable(data.frame(RF.ConfTrain$byClass)[,c('Sensitivity', 'Specificity', 'Precision','Recall','Balanced.Accuracy')], 
      caption = 'Training Data Performance')

kable(data.frame(RF.ConfValid$byClass)[,c('Sensitivity', 'Specificity', 'Precision','Recall','Balanced.Accuracy')], 
      caption = 'Validation Data Performance')
```

# Random Forest with Boosting 

```{r}
set.seed(500)
boost.mod=gbm(status_group~.,data=WaterPumps[train,],distribution="multinomial",n.trees=1000, interaction.depth=6, shrinkage=0.005)
summary(boost.mod)
# Prediction error in the training data set
boost.fitted = predict(boost.mod, newdata=WaterPumps[train,], n.trees = 500, type='response')
boost.fitted <- apply(boost.fitted, 1, which.max)
boost.fitted <- as.factor(ifelse(boost.fitted==1, 'functional',ifelse(boost.fitted==2, 'functional needs repair','non functional')))
Boost.ConfTrain=confusionMatrix(boost.fitted, train.y)

# Prediction error in the test data set
boost.predicted = predict(boost.mod, newdata=WaterPumps[valid,], n.trees = 500, type='response')
boost.predicted <- apply(boost.predicted, 1, which.max)
boost.predicted <- as.factor(ifelse(boost.predicted==1, 'functional',ifelse(boost.predicted==2, 'functional needs repair','non functional')))
Boost.ConfValid=confusionMatrix(boost.predicted, valid.y)
```

```{r}
kable(data.frame(Boost.ConfTrain$byClass)[,c('Sensitivity', 'Specificity', 'Precision','Recall','Balanced.Accuracy')], 
      caption = 'Training Data Performance')

kable(data.frame(Boost.ConfValid$byClass)[,c('Sensitivity', 'Specificity', 'Precision','Recall','Balanced.Accuracy')], 
      caption = 'Validation Data Performance')
```

## Conclusions

```{r}
Accuracy = data.frame('Model' = c('Binary Outcome Lasso','Random Forest','Boosted Random Forest'),
                      'Accuracy' = c(Binary.ConfValid$overall[['Accuracy']][[1]],RF.ConfValid$overall[['Accuracy']][[1]],
                                     Boost.ConfValid$overall[['Accuracy']][[1]]))
kable(Accuracy, caption = 'Model Comparison')
```
    

## Appendices
    - Spatial plots
    - Source code